{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7e0bce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting strands-agents\n",
      "  Downloading strands_agents-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting strands-agents-tools\n",
      "  Downloading strands_agents_tools-0.2.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting tika\n",
      "  Downloading tika-3.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents) (1.39.3)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents) (1.39.3)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from strands-agents)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting mcp<2.0.0,>=1.8.0 (from strands-agents)\n",
      "  Downloading mcp-1.12.0-py3-none-any.whl.metadata (60 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 (from strands-agents)\n",
      "  Downloading opentelemetry_instrumentation_threading-0.56b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents) (4.14.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents) (6.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents) (2.5.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents) (4.9.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting httpx>=0.27 (from mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents) (4.24.0)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Downloading sse_starlette-2.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents) (0.35.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents) (3.23.0)\n",
      "Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents)\n",
      "  Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents) (1.17.2)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-instrumentation==0.56b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.56b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents) (1.17.0)\n",
      "Collecting aws-requests-auth<0.5.0,>=0.4.3 (from strands-agents-tools)\n",
      "  Downloading aws_requests_auth-0.4.3-py2.py3-none-any.whl.metadata (567 bytes)\n",
      "Collecting botocore<2.0.0,>=1.29.0 (from strands-agents)\n",
      "  Downloading botocore-1.39.8-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools) (0.4.0)\n",
      "Collecting markdownify<2.0.0,>=1.0.0 (from strands-agents-tools)\n",
      "  Downloading markdownify-1.1.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools) (11.2.1)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools) (3.0.51)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools) (2.10.1)\n",
      "Collecting readabilipy<1.0.0,>=0.2.0 (from strands-agents-tools)\n",
      "  Downloading readabilipy-0.3.0-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: rich<15.0.0,>=14.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools) (14.0.0)\n",
      "Collecting slack-bolt<2.0.0,>=1.23.0 (from strands-agents-tools)\n",
      "  Downloading slack_bolt-1.23.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools) (1.14.0)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents-tools) (9.1.2)\n",
      "Requirement already satisfied: requests>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aws-requests-auth<0.5.0,>=0.4.3->strands-agents-tools) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdownify<2.0.0,>=1.0.0->strands-agents-tools) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4<5,>=4.9->markdownify<2.0.0,>=1.0.0->strands-agents-tools) (2.7)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools) (0.2.13)\n",
      "Collecting html5lib (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting lxml (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools)\n",
      "  Downloading lxml-6.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools) (2024.11.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools) (2.19.2)\n",
      "Collecting slack_sdk<4,>=3.35.0 (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools)\n",
      "  Downloading slack_sdk-3.36.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tika) (80.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27->mcp<2.0.0,>=1.8.0->strands-agents) (2025.6.15)\n",
      "Collecting httpcore==1.* (from httpx>=0.27->mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27->mcp<2.0.0,>=1.8.0->strands-agents) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents) (0.25.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->strands-agents-tools) (0.1.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.8.0->strands-agents)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=0.14.0->aws-requests-auth<0.5.0,>=0.4.3->strands-agents-tools) (3.4.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn>=0.23.1->mcp<2.0.0,>=1.8.0->strands-agents) (8.1.8)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from html5lib->readabilipy<1.0.0,>=0.2.0->strands-agents-tools) (0.5.1)\n",
      "Downloading strands_agents-1.0.0-py3-none-any.whl (162 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading mcp-1.12.0-py3-none-any.whl (158 kB)\n",
      "Downloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_instrumentation_threading-0.56b0-py3-none-any.whl (9.3 kB)\n",
      "Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Downloading strands_agents_tools-0.2.1-py3-none-any.whl (229 kB)\n",
      "Downloading aws_requests_auth-0.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Downloading botocore-1.39.8-py3-none-any.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m222.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdownify-1.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading readabilipy-0.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading slack_bolt-1.23.0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading slack_sdk-3.36.0-py2.py3-none-any.whl (293 kB)\n",
      "Downloading tika-3.1.0-py3-none-any.whl (38 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading sse_starlette-2.4.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-6.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m201.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-inspection, slack_sdk, python-multipart, python-dotenv, lxml, httpx-sse, httpcore, html5lib, docstring-parser, tika, slack-bolt, readabilipy, opentelemetry-api, markdownify, botocore, aws-requests-auth, sse-starlette, pydantic-settings, opentelemetry-semantic-conventions, httpx, opentelemetry-sdk, opentelemetry-instrumentation, mcp, opentelemetry-instrumentation-threading, strands-agents, strands-agents-tools\n",
      "\u001b[2K  Attempting uninstall: botocore90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/26\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Found existing installation: botocore 1.39.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/26\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Uninstalling botocore-1.39.3:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/26\u001b[0m [botocore]-api]\n",
      "\u001b[2K      Successfully uninstalled botocore-1.39.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/26\u001b[0m [botocore]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [strands-agents-tools]ands-agents-tools]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.41.3 requires botocore==1.39.3, but you have botocore 1.39.8 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aws-requests-auth-0.4.3 botocore-1.39.8 docstring-parser-0.16 html5lib-1.1 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 lxml-6.0.0 markdownify-1.1.0 mcp-1.12.0 opentelemetry-api-1.35.0 opentelemetry-instrumentation-0.56b0 opentelemetry-instrumentation-threading-0.56b0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 pydantic-settings-2.10.1 python-dotenv-1.1.1 python-multipart-0.0.20 readabilipy-0.3.0 slack-bolt-1.23.0 slack_sdk-3.36.0 sse-starlette-2.4.1 strands-agents-1.0.0 strands-agents-tools-0.2.1 tika-3.1.0 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install strands-agents strands-agents-tools tika\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3c4baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze | grep tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56148d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/tika/__init__.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __import__('pkg_resources').declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from pathlib import Path\n",
    "from tika import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b64680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_model = BedrockModel(\n",
    "  model_id=\"amazon.nova-lite-v1:0\", \n",
    "  region_name=\"us-east-1\",\n",
    "  temperature=0.3,\n",
    "  streaming=True, # Enable/disable streaming\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0ca8d",
   "metadata": {},
   "source": [
    "## Job description analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28db472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "class MustHaveRequirementSkills(BaseModel):\n",
    "    \"\"\"\"\"\"\n",
    "    technical_skills: Optional[str]\n",
    "    experience: Optional[str]\n",
    "    qualifications: Optional[List[str]]\n",
    "    core_responsibilities: Optional[List[str]]\n",
    "            \n",
    "class GoodToHaveRequirementSkills(BaseModel):\n",
    "    \"\"\"\"\"\"\n",
    "    additional_skills: Optional[List[str]]\n",
    "    experience: Optional[str]\n",
    "    qualifications: Optional[List[str]]\n",
    "    core_responsibilities: Optional[List[str]]\n",
    "\n",
    "class AdditionalScreeningCriteria(BaseModel):\n",
    "    \"\"\"\"\"\"\n",
    "    workpolicy_conditions: Optional[str]\n",
    "    general_constrains: Optional[List[str]]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf8fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobDescripiton(BaseModel):\n",
    "    \"\"\"Schema for Job Description\"\"\"\n",
    "    original_job_description: str = Field(description=\"The complete original job description text\")\n",
    "    musthave_requirementskills: List[MustHaveRequirementSkills] = Field(description=\"List of must have requirement skills\")\n",
    "    goodtohave_requirementskills: List[GoodToHaveRequirementSkills]= Field(description=\"List of good to have requirement skills\")\n",
    "    additional_screening_criteria: List[AdditionalScreeningCriteria] = Field(description = \"List of additional screening Criteria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c701ba",
   "metadata": {},
   "source": [
    "## Parse document via Tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da9a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf(document_path:str):\n",
    "    parsed_pdf = parser.from_file(document_path)\n",
    "    # saving content of pdf\n",
    "    # you can also bring text only, by parsed_pdf['text'] \n",
    "    # parsed_pdf['content'] returns string \n",
    "    str_content = parsed_pdf['content'] \n",
    "    return str_content\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0168c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_jd= parse_pdf(\"data/ML- JobDescription.pdf\")\n",
    "parsed_resume = parse_pdf(\"data/resume.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b89c9",
   "metadata": {},
   "source": [
    "### Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77512c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareFields(BaseModel):\n",
    "    musthave_requirementskills: Dict[str, bool] = Field(description=\"Dictionary of must have requirements with boolean values\")\n",
    "    goodtohave_requirementskills: Dict[str, bool]= Field(description=\"Dictionary of good to have requirements with boolean values\")\n",
    "    additional_screening_criteria: Dict[str, bool] = Field(description=\"Dictionary of additional screening requirements with boolean values\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9bfc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "class QuantitativeResumeCheck(BaseModel):\n",
    "    \"Schema for Resume JD Qualitative Check\"\"\"\n",
    "    requirement_match: List[CompareFields] = Field(description=\"Dictionary of fields with boolean values\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d714b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualitativeResumeCheck(BaseModel):\n",
    "    inferred_skills: str = Field(description=\"Inference from candidates profile\")\n",
    "    project_gravity: str = Field(description=\"Impact of candidates projects\")\n",
    "    ownership_initiative: str = Field(description=\"Has candidate taken initative in work\")\n",
    "    transferability_torole:str = Field(description=\"How easy it be was for candidate onboarding\")\n",
    "    bonus_experience: str = Field(description=\"Matches any good to have skills from job description\")\n",
    "    recrruiter_summary:str = Field(description=\"Summary by the recruiter\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae4f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description_agent = Agent(\n",
    "    system_prompt=(f\"\"\"\n",
    "      You are an experienced resume evaluator. Extract the componenets of the resume in the following format\n",
    "        \n",
    "        Extract all Must Have Responsibilities:\n",
    "        -Technical Skills: Essential technical skills\n",
    "        -Experience: Minimum years and type of relevant experience\n",
    "        -Qualifications: Mandatory degrees or certifications\n",
    "        -Core Responsibilities: Key duties that are non-negotiable\n",
    "\n",
    "\n",
    "        -Extract all Good-to-Have Requirements:\n",
    "\n",
    "        -Additional Skills: Preferred technical skills\n",
    "        -Extra Qualifications: Bonus education or certifications\n",
    "        -Bonus Experience: Extra experience that could add value\n",
    "\n",
    "\n",
    "        Extract any Additional Screening Criteria:\n",
    "\n",
    "        -Filtering statements that affect eligibility\n",
    "        -Work policy conditions\n",
    "        -Availability constraints\n",
    "        -Discriminatory or biased phrasing\n",
    "        -Anything else that significantly affects who should or shouldn't apply\n",
    "\n",
    "    \n",
    "        \"\"\"\n",
    "    ), model = bedrock_model\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab432c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_jd_agent_quantative= Agent(\n",
    "system_prompt = (f\"\"\"\n",
    "You are a recruiter evaluating a candidate's resume against a given job_description json inputs. Compare the candidates resume against given job description. Evaluate whether the candidate meets the necessary requirements.\n",
    "\n",
    "Step 1: Quantitative Check\n",
    "Perform a Boolean (true/false) check for each requirement based on the candidate's resume:\n",
    "\n",
    "-For each skill listed in must_have_requirements and good_to_have_requirements of jobdescription, determine if the candidate possesses it. Return true or false for each.\n",
    "-For each core_responsibility mentioned in jobdescription, determine if the candidate resume has demonstrated it in their past work. Return true or false.\n",
    "-For each additional_screening_criteria in jobdescription, return a boolean value indicating whether the candidates resume meets the condition (e.g., full-time, onsite position, work authorization, etc.).\n",
    "\n",
    "\"\"\"),\n",
    "model = bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64cd6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_jd_agent_qualitativecheck = Agent(\n",
    "system_prompt = (\"\"\"\n",
    "\n",
    "Step 2: Qualitative Check\n",
    "Now, switch to a recruiter-style qualitative assessment. Use your intuition like a human — go beyond what's explicitly stated. Read between the lines, infer intent, and use contextual clues from the resume and the JD to judge fit. Reference the results from Step 1 as part of your reasoning.\n",
    "\n",
    "    Assess the following:\n",
    "\n",
    "    -Inferred Skills: What skills can you infer from the candidate's projects or roles?\n",
    "    -Project Gravity: Were the projects academic or real-world, high-impact, production-ready, etc.?\n",
    "    -Ownership and Initiative: Did the candidate lead the work? Show initiative? Or just follow directions?\n",
    "    -Transferability to Role: How well would their experience transfer to this particular role? Will they onboard quickly?\n",
    "    -Bonus Experience & Extra Qualifications: If the JD lists any bonus criteria (e.g., fintech, B2B SaaS), consider that a positive signal even if not part of Step 1.\n",
    "    -Recruiter Style Summary: Provide a recruiter style summary of the full profile of the candidate, consider the results of both the quantitative and qualitative assessment.\n",
    "\n",
    "\"\"\"),model = bedrock_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a43b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_finalrecommendation = Agent(\n",
    "system_prompt = (\"\"\"\n",
    "\n",
    "Step 2: Final Recommendation\n",
    "Now, as a recruiter, take the final call if the candidate is the right fit for the role.Based on the summary provided. Keep the tone practitcal.\n",
    "\n",
    "\n",
    "\"\"\"),model = bedrock_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55872a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def process_workflow(parsed_jd, parsed_resume):\n",
    "\n",
    "    job_description_response = job_description_agent.structured_output(JobDescripiton, parsed_jd)\n",
    "    \n",
    "    # Step 1: Qualitative Resume Analysis\n",
    "\n",
    "    append_para = [str(job_description_response), parsed_resume]\n",
    "    jd_resume = \"\\n\\n\".join(append_para)\n",
    "\n",
    "    resume_agent_quanitativecheck = resume_jd_agent_quantative(jd_resume)\n",
    "\n",
    "\n",
    "    #Step 2: Qualitative Resume Analysis\n",
    "    resume_agent_qualitativecheck = resume_jd_agent_qualitativecheck(str(resume_agent_quanitativecheck))\n",
    "    \n",
    "\n",
    "    # Step 3: Final Report\n",
    "    final_report = resume_finalrecommendation(str(resume_agent_qualitativecheck))\n",
    "\n",
    "    return  final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fe771f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking> To extract the components of the resume, I need to identify the must-have responsibilities, good-to-have requirements, and additional screening criteria from the provided job description. I will categorize each requirement accordingly. </thinking>\n",
      "\n",
      "Tool #3: JobDescripiton\n",
      "Based on the provided job description and the candidate's resume, here is a quantitative evaluation of whether the candidate meets the necessary requirements:\n",
      "\n",
      "### Must Have Requirements\n",
      "\n",
      "#### Skills\n",
      "- **Strong proficiency in Python and Java, as well as other programming languages used in machine learning.**\n",
      "  - **True**: The candidate lists proficiency in Python, deep learning frameworks (PyTorch, MXNet), R, and C/C++.\n",
      "\n",
      "- **Experience with TensorFlow, PyTorch, Keras, and scikit-learn.**\n",
      "  - **Partially True**: The candidate lists proficiency in PyTorch and scikit-learn but does not mention TensorFlow or Keras.\n",
      "\n",
      "#### Experience\n",
      "- **3-5 years of experience in machine learning, data engineering, or software development.**\n",
      "  - **True**: The candidate has over 5 years of post-PhD experience in ML/AI.\n",
      "\n",
      "#### Qualifications\n",
      "- **Bachelor's degree or master's degree in computer science, data science, or a related field.**\n",
      "  - **True**: The candidate has a Doctor of Philosophy in Computational Biology from PSL Research University, Paris, France.\n",
      "\n",
      "#### Core Responsibilities\n",
      "- **Designing and developing machine learning models.**\n",
      "  - **True**: The candidate has experience in developing novel ML methods and advanced scientific discoveries in biology and cancer research.\n",
      "\n",
      "- **Implementing data pipelines.**\n",
      "  - **True**: The candidate proposed a data pipeline during an internship at Roche Diagnostics GmbH.\n",
      "\n",
      "- **Collaborating across teams.**\n",
      "  - **True**: The candidate has worked in cross-functional teams at Amazon.\n",
      "\n",
      "- **Optimizing model performance.**\n",
      "  - **True**: The candidate has experience in fine-tuning techniques to maximize model performance.\n",
      "\n",
      "- **Developing prototypes.**\n",
      "  - **True**: The candidate delivered a deep generative model for ‘universal’ speech synthesis.\n",
      "\n",
      "- **Managing machine learning systems.**\n",
      "  - **True**: The candidate collaborated with engineers to scale up Alexa TTS production.\n",
      "\n",
      "- **Implementing feature engineering.**\n",
      "  - **True**: The candidate developed and optimized features from raw data.\n",
      "\n",
      "- **Automating model training and deployment.**\n",
      "  - **True**: The candidate worked on automating the Alexa TTS production.\n",
      "\n",
      "- **Continuous learning and skill improvement.**\n",
      "  - **True**: The candidate has a history of staying updated with the latest ML frameworks and programming languages.\n",
      "\n",
      "### Good To Have Requirements\n",
      "\n",
      "#### Skills\n",
      "- **Data handling skills and proficiency in data structures, data modeling, and data visualization.**\n",
      "  - **True**: The candidate has experience in processing large-scale unstructured data and building models.\n",
      "\n",
      "### Additional Screening Criteria\n",
      "- **General Constraints**\n",
      "  - **N/A**: No specific constraints mentioned.\n",
      "\n",
      "### Summary\n",
      "- **Must Have Requirements**:\n",
      "  - Skills: Partially True (missing TensorFlow and Keras)\n",
      "  - Experience: True\n",
      "  - Qualifications: True\n",
      "  - Core Responsibilities: All True\n",
      "\n",
      "- **Good To Have Requirements**:\n",
      "  - Skills: True\n",
      "\n",
      "- **Additional Screening Criteria**: N/A\n",
      "\n",
      "Based on this evaluation, the candidate meets most of the necessary requirements for the Machine Learning Engineer position but is missing experience with TensorFlow and Keras. This is a minor gap, but it could be a point of consideration during the interview process."
     ]
    },
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nInvalid type for parameter messages[0].content, value: Based on the provided job description and the candidate's resume, here is a quantitative evaluation of whether the candidate meets the necessary requirements:\n\n### Must Have Requirements\n\n#### Skills\n- **Strong proficiency in Python and Java, as well as other programming languages used in machine learning.**\n  - **True**: The candidate lists proficiency in Python, deep learning frameworks (PyTorch, MXNet), R, and C/C++.\n\n- **Experience with TensorFlow, PyTorch, Keras, and scikit-learn.**\n  - **Partially True**: The candidate lists proficiency in PyTorch and scikit-learn but does not mention TensorFlow or Keras.\n\n#### Experience\n- **3-5 years of experience in machine learning, data engineering, or software development.**\n  - **True**: The candidate has over 5 years of post-PhD experience in ML/AI.\n\n#### Qualifications\n- **Bachelor's degree or master's degree in computer science, data science, or a related field.**\n  - **True**: The candidate has a Doctor of Philosophy in Computational Biology from PSL Research University, Paris, France.\n\n#### Core Responsibilities\n- **Designing and developing machine learning models.**\n  - **True**: The candidate has experience in developing novel ML methods and advanced scientific discoveries in biology and cancer research.\n\n- **Implementing data pipelines.**\n  - **True**: The candidate proposed a data pipeline during an internship at Roche Diagnostics GmbH.\n\n- **Collaborating across teams.**\n  - **True**: The candidate has worked in cross-functional teams at Amazon.\n\n- **Optimizing model performance.**\n  - **True**: The candidate has experience in fine-tuning techniques to maximize model performance.\n\n- **Developing prototypes.**\n  - **True**: The candidate delivered a deep generative model for ‘universal’ speech synthesis.\n\n- **Managing machine learning systems.**\n  - **True**: The candidate collaborated with engineers to scale up Alexa TTS production.\n\n- **Implementing feature engineering.**\n  - **True**: The candidate developed and optimized features from raw data.\n\n- **Automating model training and deployment.**\n  - **True**: The candidate worked on automating the Alexa TTS production.\n\n- **Continuous learning and skill improvement.**\n  - **True**: The candidate has a history of staying updated with the latest ML frameworks and programming languages.\n\n### Good To Have Requirements\n\n#### Skills\n- **Data handling skills and proficiency in data structures, data modeling, and data visualization.**\n  - **True**: The candidate has experience in processing large-scale unstructured data and building models.\n\n### Additional Screening Criteria\n- **General Constraints**\n  - **N/A**: No specific constraints mentioned.\n\n### Summary\n- **Must Have Requirements**:\n  - Skills: Partially True (missing TensorFlow and Keras)\n  - Experience: True\n  - Qualifications: True\n  - Core Responsibilities: All True\n\n- **Good To Have Requirements**:\n  - Skills: True\n\n- **Additional Screening Criteria**: N/A\n\nBased on this evaluation, the candidate meets most of the necessary requirements for the Machine Learning Engineer position but is missing experience with TensorFlow and Keras. This is a minor gap, but it could be a point of consideration during the interview process.\n, type: <class 'strands.agent.agent_result.AgentResult'>, valid types: <class 'list'>, <class 'tuple'>\nInvalid type for parameter messages[1].content, value: Based on the provided job description and the candidate's resume, here is a quantitative evaluation of whether the candidate meets the necessary requirements:\n\n### Must Have Requirements\n\n#### Skills\n- **Strong proficiency in Python and Java, as well as other programming languages used in machine learning.**\n  - **True**: The candidate lists proficiency in Python, deep learning frameworks (PyTorch, MXNet), R, and C/C++.\n\n- **Experience with TensorFlow, PyTorch, Keras, and scikit-learn.**\n  - **Partially True**: The candidate lists proficiency in PyTorch and scikit-learn but does not mention TensorFlow or Keras.\n\n#### Experience\n- **3-5 years of experience in machine learning, data engineering, or software development.**\n  - **True**: The candidate has over 5 years of post-PhD experience in ML/AI.\n\n#### Qualifications\n- **Bachelor's degree or master's degree in computer science, data science, or a related field.**\n  - **True**: The candidate has a Doctor of Philosophy in Computational Biology from PSL Research University, Paris, France.\n\n#### Core Responsibilities\n- **Designing and developing machine learning models.**\n  - **True**: The candidate has experience in developing novel ML methods and advanced scientific discoveries in biology and cancer research.\n\n- **Implementing data pipelines.**\n  - **True**: The candidate proposed a data pipeline during an internship at Roche Diagnostics GmbH.\n\n- **Collaborating across teams.**\n  - **True**: The candidate has worked in cross-functional teams at Amazon.\n\n- **Optimizing model performance.**\n  - **True**: The candidate has experience in fine-tuning techniques to maximize model performance.\n\n- **Developing prototypes.**\n  - **True**: The candidate delivered a deep generative model for ‘universal’ speech synthesis.\n\n- **Managing machine learning systems.**\n  - **True**: The candidate collaborated with engineers to scale up Alexa TTS production.\n\n- **Implementing feature engineering.**\n  - **True**: The candidate developed and optimized features from raw data.\n\n- **Automating model training and deployment.**\n  - **True**: The candidate worked on automating the Alexa TTS production.\n\n- **Continuous learning and skill improvement.**\n  - **True**: The candidate has a history of staying updated with the latest ML frameworks and programming languages.\n\n### Good To Have Requirements\n\n#### Skills\n- **Data handling skills and proficiency in data structures, data modeling, and data visualization.**\n  - **True**: The candidate has experience in processing large-scale unstructured data and building models.\n\n### Additional Screening Criteria\n- **General Constraints**\n  - **N/A**: No specific constraints mentioned.\n\n### Summary\n- **Must Have Requirements**:\n  - Skills: Partially True (missing TensorFlow and Keras)\n  - Experience: True\n  - Qualifications: True\n  - Core Responsibilities: All True\n\n- **Good To Have Requirements**:\n  - Skills: True\n\n- **Additional Screening Criteria**: N/A\n\nBased on this evaluation, the candidate meets most of the necessary requirements for the Machine Learning Engineer position but is missing experience with TensorFlow and Keras. This is a minor gap, but it could be a point of consideration during the interview process.\n, type: <class 'strands.agent.agent_result.AgentResult'>, valid types: <class 'list'>, <class 'tuple'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43mprocess_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_jd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_resume\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;28mprint\u001b[39m(chunk, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 15\u001b[0m, in \u001b[0;36mprocess_workflow\u001b[0;34m(parsed_jd, parsed_resume)\u001b[0m\n\u001b[1;32m     11\u001b[0m resume_agent_quanitativecheck \u001b[38;5;241m=\u001b[39m resume_jd_agent_quantative(jd_resume)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#Step 2: Qualitative Resume Analysis\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m resume_agent_qualitativecheck \u001b[38;5;241m=\u001b[39m \u001b[43mresume_jd_agent_qualitativecheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresume_agent_quanitativecheck\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Step 3: Final Report\u001b[39;00m\n\u001b[1;32m     19\u001b[0m final_report \u001b[38;5;241m=\u001b[39m resume_finalrecommendation(\u001b[38;5;28mstr\u001b[39m(resume_agent_qualitativecheck))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:379\u001b[0m, in \u001b[0;36mAgent.__call__\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    378\u001b[0m     future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(execute)\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001b[0m, in \u001b[0;36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001b[0;34m(*func_args, **func_kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     token \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mattach(otel_context)\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:375\u001b[0m, in \u001b[0;36mAgent.__call__.<locals>.execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentResult:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/asyncio/runners.py:44\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         loop\u001b[38;5;241m.\u001b[39mset_debug(debug)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py:649\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:400\u001b[0m, in \u001b[0;36mAgent.invoke_async\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process a natural language prompt through the agent's event loop.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03mThis method implements the conversational interface (e.g., `agent(\"hello!\")`). It adds the user's prompt to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m        - state: The final state of the event loop\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_async(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m    401\u001b[0m     _ \u001b[38;5;241m=\u001b[39m event\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(AgentResult, event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:510\u001b[0m, in \u001b[0;36mAgent.stream_async\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m     events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_loop(message, invocation_state\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[1;32m    512\u001b[0m             callback_handler(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mevent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:546\u001b[0m, in \u001b[0;36mAgent._run_loop\u001b[0;34m(self, message, invocation_state)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Execute the event loop cycle with retry logic for context limits\u001b[39;00m\n\u001b[1;32m    545\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_event_loop_cycle(invocation_state)\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# Signal from the model provider that the message sent by the user should be redacted,\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# likely due to a guardrail.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    550\u001b[0m         event\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredactContent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredactContent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredactUserContentMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    554\u001b[0m     ):\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    556\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredactContent\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredactUserContentMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m    557\u001b[0m         ]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:585\u001b[0m, in \u001b[0;36mAgent._execute_event_loop_cycle\u001b[0;34m(self, invocation_state)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# Execute the main event loop cycle\u001b[39;00m\n\u001b[1;32m    581\u001b[0m     events \u001b[38;5;241m=\u001b[39m event_loop_cycle(\n\u001b[1;32m    582\u001b[0m         agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    583\u001b[0m         invocation_state\u001b[38;5;241m=\u001b[39minvocation_state,\n\u001b[1;32m    584\u001b[0m     )\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ContextWindowOverflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# Try reducing the context size and retrying\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/event_loop/event_loop.py:182\u001b[0m, in \u001b[0;36mevent_loop_cycle\u001b[0;34m(agent, invocation_state)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_loop_throttled_delay\u001b[39m\u001b[38;5;124m\"\u001b[39m: current_delay, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minvocation_state}}\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Add message in trace and mark the end of the stream messages trace\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     stream_trace\u001b[38;5;241m.\u001b[39madd_message(message)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/event_loop/event_loop.py:130\u001b[0m, in \u001b[0;36mevent_loop_cycle\u001b[0;34m(agent, invocation_state)\u001b[0m\n\u001b[1;32m    120\u001b[0m agent\u001b[38;5;241m.\u001b[39mhooks\u001b[38;5;241m.\u001b[39minvoke_callbacks(\n\u001b[1;32m    121\u001b[0m     BeforeModelInvocationEvent(\n\u001b[1;32m    122\u001b[0m         agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# TODO: To maintain backwards compatibility, we need to combine the stream event with invocation_state\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m#       before yielding to the callback handler. This will be revisited when migrating to strongly\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m#       typed events.\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m stream_messages(agent\u001b[38;5;241m.\u001b[39mmodel, agent\u001b[38;5;241m.\u001b[39msystem_prompt, agent\u001b[38;5;241m.\u001b[39mmessages, tool_specs):\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[1;32m    132\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m {\n\u001b[1;32m    133\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mevent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(invocation_state \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m {})}\n\u001b[1;32m    134\u001b[0m             }\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/event_loop/streaming.py:318\u001b[0m, in \u001b[0;36mstream_messages\u001b[0;34m(model, system_prompt, messages, tool_specs)\u001b[0m\n\u001b[1;32m    314\u001b[0m messages \u001b[38;5;241m=\u001b[39m remove_blank_messages_content_text(messages)\n\u001b[1;32m    316\u001b[0m chunks \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstream(messages, tool_specs \u001b[38;5;28;01mif\u001b[39;00m tool_specs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, system_prompt)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m process_stream(chunks):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/event_loop/streaming.py:273\u001b[0m, in \u001b[0;36mprocess_stream\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    270\u001b[0m usage: Usage \u001b[38;5;241m=\u001b[39m Usage(inputTokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, outputTokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, totalTokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    271\u001b[0m metrics: Metrics \u001b[38;5;241m=\u001b[39m Metrics(latencyMs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m: chunk}}\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessageStart\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/models/bedrock.py:350\u001b[0m, in \u001b[0;36mBedrockModel.stream\u001b[0;34m(self, messages, tool_specs, system_prompt, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m task\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/asyncio/threads.py:25\u001b[0m, in \u001b[0;36mto_thread\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m ctx \u001b[38;5;241m=\u001b[39m contextvars\u001b[38;5;241m.\u001b[39mcopy_context()\n\u001b[1;32m     24\u001b[0m func_call \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(ctx\u001b[38;5;241m.\u001b[39mrun, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mrun_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001b[0m, in \u001b[0;36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001b[0;34m(*func_args, **func_kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     token \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mattach(otel_context)\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/models/bedrock.py:384\u001b[0m, in \u001b[0;36mBedrockModel._stream\u001b[0;34m(self, callback, messages, tool_specs, system_prompt)\u001b[0m\n\u001b[1;32m    382\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot response from model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n\u001b[0;32m--> 384\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverse_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk\n\u001b[1;32m    388\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguardrail\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    390\u001b[0m         ):\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:601\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1031\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m properties:\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;66;03m# Pass arbitrary endpoint info with the Request\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;66;03m# for use during construction.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m     request_context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendpoint_properties\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m properties\n\u001b[0;32m-> 1031\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_request_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m resolve_checksum_context(request_dict, operation_model, api_params)\n\u001b[1;32m   1040\u001b[0m service_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1098\u001b[0m, in \u001b[0;36mBaseClient._convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, endpoint_url, context, headers, set_user_agent_header)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_convert_to_request_dict\u001b[39m(\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1091\u001b[0m     api_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     set_user_agent_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1097\u001b[0m ):\n\u001b[0;32m-> 1098\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_to_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39minject_host_prefix:\n\u001b[1;32m   1102\u001b[0m         request_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/validate.py:381\u001b[0m, in \u001b[0;36mParamValidationDecorator.serialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    377\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_validator\u001b[38;5;241m.\u001b[39mvalidate(\n\u001b[1;32m    378\u001b[0m         parameters, operation_model\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report\u001b[38;5;241m.\u001b[39mhas_errors():\n\u001b[0;32m--> 381\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParamValidationError(report\u001b[38;5;241m=\u001b[39mreport\u001b[38;5;241m.\u001b[39mgenerate_report())\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serializer\u001b[38;5;241m.\u001b[39mserialize_to_request(\n\u001b[1;32m    383\u001b[0m     parameters, operation_model\n\u001b[1;32m    384\u001b[0m )\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nInvalid type for parameter messages[0].content, value: Based on the provided job description and the candidate's resume, here is a quantitative evaluation of whether the candidate meets the necessary requirements:\n\n### Must Have Requirements\n\n#### Skills\n- **Strong proficiency in Python and Java, as well as other programming languages used in machine learning.**\n  - **True**: The candidate lists proficiency in Python, deep learning frameworks (PyTorch, MXNet), R, and C/C++.\n\n- **Experience with TensorFlow, PyTorch, Keras, and scikit-learn.**\n  - **Partially True**: The candidate lists proficiency in PyTorch and scikit-learn but does not mention TensorFlow or Keras.\n\n#### Experience\n- **3-5 years of experience in machine learning, data engineering, or software development.**\n  - **True**: The candidate has over 5 years of post-PhD experience in ML/AI.\n\n#### Qualifications\n- **Bachelor's degree or master's degree in computer science, data science, or a related field.**\n  - **True**: The candidate has a Doctor of Philosophy in Computational Biology from PSL Research University, Paris, France.\n\n#### Core Responsibilities\n- **Designing and developing machine learning models.**\n  - **True**: The candidate has experience in developing novel ML methods and advanced scientific discoveries in biology and cancer research.\n\n- **Implementing data pipelines.**\n  - **True**: The candidate proposed a data pipeline during an internship at Roche Diagnostics GmbH.\n\n- **Collaborating across teams.**\n  - **True**: The candidate has worked in cross-functional teams at Amazon.\n\n- **Optimizing model performance.**\n  - **True**: The candidate has experience in fine-tuning techniques to maximize model performance.\n\n- **Developing prototypes.**\n  - **True**: The candidate delivered a deep generative model for ‘universal’ speech synthesis.\n\n- **Managing machine learning systems.**\n  - **True**: The candidate collaborated with engineers to scale up Alexa TTS production.\n\n- **Implementing feature engineering.**\n  - **True**: The candidate developed and optimized features from raw data.\n\n- **Automating model training and deployment.**\n  - **True**: The candidate worked on automating the Alexa TTS production.\n\n- **Continuous learning and skill improvement.**\n  - **True**: The candidate has a history of staying updated with the latest ML frameworks and programming languages.\n\n### Good To Have Requirements\n\n#### Skills\n- **Data handling skills and proficiency in data structures, data modeling, and data visualization.**\n  - **True**: The candidate has experience in processing large-scale unstructured data and building models.\n\n### Additional Screening Criteria\n- **General Constraints**\n  - **N/A**: No specific constraints mentioned.\n\n### Summary\n- **Must Have Requirements**:\n  - Skills: Partially True (missing TensorFlow and Keras)\n  - Experience: True\n  - Qualifications: True\n  - Core Responsibilities: All True\n\n- **Good To Have Requirements**:\n  - Skills: True\n\n- **Additional Screening Criteria**: N/A\n\nBased on this evaluation, the candidate meets most of the necessary requirements for the Machine Learning Engineer position but is missing experience with TensorFlow and Keras. This is a minor gap, but it could be a point of consideration during the interview process.\n, type: <class 'strands.agent.agent_result.AgentResult'>, valid types: <class 'list'>, <class 'tuple'>\nInvalid type for parameter messages[1].content, value: Based on the provided job description and the candidate's resume, here is a quantitative evaluation of whether the candidate meets the necessary requirements:\n\n### Must Have Requirements\n\n#### Skills\n- **Strong proficiency in Python and Java, as well as other programming languages used in machine learning.**\n  - **True**: The candidate lists proficiency in Python, deep learning frameworks (PyTorch, MXNet), R, and C/C++.\n\n- **Experience with TensorFlow, PyTorch, Keras, and scikit-learn.**\n  - **Partially True**: The candidate lists proficiency in PyTorch and scikit-learn but does not mention TensorFlow or Keras.\n\n#### Experience\n- **3-5 years of experience in machine learning, data engineering, or software development.**\n  - **True**: The candidate has over 5 years of post-PhD experience in ML/AI.\n\n#### Qualifications\n- **Bachelor's degree or master's degree in computer science, data science, or a related field.**\n  - **True**: The candidate has a Doctor of Philosophy in Computational Biology from PSL Research University, Paris, France.\n\n#### Core Responsibilities\n- **Designing and developing machine learning models.**\n  - **True**: The candidate has experience in developing novel ML methods and advanced scientific discoveries in biology and cancer research.\n\n- **Implementing data pipelines.**\n  - **True**: The candidate proposed a data pipeline during an internship at Roche Diagnostics GmbH.\n\n- **Collaborating across teams.**\n  - **True**: The candidate has worked in cross-functional teams at Amazon.\n\n- **Optimizing model performance.**\n  - **True**: The candidate has experience in fine-tuning techniques to maximize model performance.\n\n- **Developing prototypes.**\n  - **True**: The candidate delivered a deep generative model for ‘universal’ speech synthesis.\n\n- **Managing machine learning systems.**\n  - **True**: The candidate collaborated with engineers to scale up Alexa TTS production.\n\n- **Implementing feature engineering.**\n  - **True**: The candidate developed and optimized features from raw data.\n\n- **Automating model training and deployment.**\n  - **True**: The candidate worked on automating the Alexa TTS production.\n\n- **Continuous learning and skill improvement.**\n  - **True**: The candidate has a history of staying updated with the latest ML frameworks and programming languages.\n\n### Good To Have Requirements\n\n#### Skills\n- **Data handling skills and proficiency in data structures, data modeling, and data visualization.**\n  - **True**: The candidate has experience in processing large-scale unstructured data and building models.\n\n### Additional Screening Criteria\n- **General Constraints**\n  - **N/A**: No specific constraints mentioned.\n\n### Summary\n- **Must Have Requirements**:\n  - Skills: Partially True (missing TensorFlow and Keras)\n  - Experience: True\n  - Qualifications: True\n  - Core Responsibilities: All True\n\n- **Good To Have Requirements**:\n  - Skills: True\n\n- **Additional Screening Criteria**: N/A\n\nBased on this evaluation, the candidate meets most of the necessary requirements for the Machine Learning Engineer position but is missing experience with TensorFlow and Keras. This is a minor gap, but it could be a point of consideration during the interview process.\n, type: <class 'strands.agent.agent_result.AgentResult'>, valid types: <class 'list'>, <class 'tuple'>"
     ]
    }
   ],
   "source": [
    "for chunk in process_workflow(parsed_jd, parsed_resume).message['content'][0]['text']:\n",
    "        print(chunk, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244fc22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
